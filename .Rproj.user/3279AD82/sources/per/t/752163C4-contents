---
title: "Lista 2"
subtitle: "Modelos Lineares Generalizados - 2/2023" 
author:
  - César Augusto Galvão - 19/0011572
  - Laiza Mendes - 20/0067028
format: 
  pdf:
    toc: true
    toc-depth: 3
    keep-tex: true
    include-in-header:
      text: |
        \usepackage[auth-lg]{authblk}
execute:
  echo: false
  message: false
  warning: false
---

{{< pagebreak >}}

```{r setup, include = FALSE}
if(!("pacman" %in% installed.packages())){install.packages("pacman")}

pacman::p_load(tidyverse, tidymodels, kableExtra, corrplot, plotrix, lmtest, psych, car, phia, cowplot, MASS, corrplot)
```


# Questão 1

Considere os dados sobre a qualidade do vinho tinto, apresentados no ficheiro `Q01-data.txt`. Ajuste o modelo de regressão linear múltipla, e faça uma análise completa desses dados. Que conclusões você tira dessa análise? (use 5% de significância durantes as análises).

Uma amostra dos dados é exibida na tabela a seguir:

```{r}

#Lendo e fazendo uma primeira observação das variáveis
dados_qualidade_vinho <- read.table("dados lista 2/Q01_data.txt", header=T)

head(dados_qualidade_vinho)%>%
  knitr::kable(
    format = "latex",
    align = c("c"),
    booktabs = TRUE,
    longtable = TRUE,
    linesep = "",
    escape = FALSE,
    digits = 2
    ) %>%
  kableExtra::kable_styling(
      position = "center",
      latex_options = c("striped", "repeat_header"),
      stripe_color = "gray!15")

```

Cada variável do banco de dados apresenta as seguintes características:

\begin{itemize}
  \item y: classificação de qualidade (20 no maximo);
  \item x1: variedade de vinho (0 — Cabernet Sauvignon, 1 — Shiraz);
  \item x2: nível de pH;
  \item x3: SO2 total (ppm);
  \item x4: densidade de cor;
  \item x5: cor de vinho;
  \item x6: cor de pigmento polimérico;
  \item x7: cor de antocianina;
  \item x8: antocianinas totais (g/L);
  \item x9: grau de ionização das antocianinas (porcentagem);
  \item x10: antocianinas ionizadas (porcentagem).
\end{itemize}

{{< pagebreak >}}



```{r, include = FALSE}

# Resumo estatístico dos dados
# 
# summary(dados_qualidade_vinho[, 1:6])%>%
#   knitr::kable(
#     format = "latex",
#     align = c("c"),
#     booktabs = TRUE,
#     longtable = TRUE,
#     linesep = "",
#     escape = FALSE,
#     digits = 2
#     ) %>%
#   kableExtra::kable_styling(
#       position = "center",
#       latex_options = c("striped", "repeat_header"),
#       stripe_color = "gray!15")
# 
# 
# 
# summary(dados_qualidade_vinho[, 7:11])%>%
#   knitr::kable(
#     format = "latex",
#     align = c("c"),
#     booktabs = TRUE,
#     longtable = TRUE,
#     linesep = "",
#     escape = FALSE,
#     digits = 2
#     ) %>%
#   kableExtra::kable_styling(
#       position = "center",
#       latex_options = c("striped", "repeat_header"),
#       stripe_color = "gray!15")

```


Diante dos dados acima, para a aplicação de um modelo de regressão é necessário verificar os níveis de correlação entre as variáveis. Com isso, podemos ter uma noção de quais variáveis podem apresentar multicolinearidade num modelo de regressão linear múltiplo.


```{r, fig.height = 4, fig.align='center', fig.cap = "Correlograma das variáveis disponíveis"}

#Analisando as possíveis correlações entre as variáveis

#Correlação
cor <- cor(dados_qualidade_vinho)

##Visualização da correlação
corrplot::corrplot(cor, method = "color",
                   type = "full",
                   order = "hclust",
                   addCoef.col = "black",
                   tl.srt = 50,
                   diag = T, 
                   number.cex = 0.7)

```

```{r, fig.height = 5, fig.align='center', fig.cap = "Correlações dois a dois das variáveis disponíveis."}

#Analisando as possíveis correlações entre as variáveis

pairs(dados_qualidade_vinho, col= "navy", gap=0.2, pch = 19)

```

{{< pagebreak >}}

Nota-se a partir dos gráficos apresentados que:

\begin{itemize}
  \item A variável x1 tem apenas correlações fracas;
  \item A variável x2 tem apenas uma correlação negativa moderada com x3;
  \item A variável x3 tem correlação moderada com todas as variáveis, exceto com x1;
  \item A variável x4 tem correlação forte positiva com y, x5, x6, x7, x9, x10, além de uma correlação moderada negativa com x3;
  \item A variável x5 tem correlação forte positiva com y, x4, x6, x7, x9, x10, além de uma correlação moderada negativa com x3;
  \item A variável x6 tem correlação forte positiva com y, x4, x5, x7, x10, além de uma correlação moderada negativa e positiva com, respectivamente, x3 e x9;
  \item A variável x7 tem correlação forte positiva com x4, x5, x6, x9, correlação moderada negativa e positiva com, respectivamente, x3 e y, além de uma correlação perfeita com x10;
  \item A variável x8 tem apenas correlação moderada positiva e negativa, respectivamente, com x3 e x9;
  \item A variável x9 tem correlação forte positiva com x4, x5, x7, x10, além de uma correlação moderada positiva com y e x6 e negativa com x3 e x8;
  \item A variável x10 tem correlação forte positiva com x4, x5, x6, x9, correlação moderada positiva com y e negativa com x3, além de uma correlação perfeita com x7.
\end{itemize}

Independentemente das correlações, vamos aplicar um modelo de regressão linear múltiplo completo, com todas as variáveis, para analisar e modelar  a relação entre a variável dependente ou resposta $y$ e as variáveis independentes ou explicativas $x_i \ \forall \ i =  \{ 1,2,\dots,10 \}$. 

```{r}

# Ajustando o Modelo de Regressão Múltipla
modelo_reg_multi <- lm(y~., data=dados_qualidade_vinho)

summary(modelo_reg_multi) %>% 
  tidy() %>%
  knitr::kable(
    format = "latex",
    align = c("lcccc"),
    booktabs = TRUE,
    longtable = TRUE,
    linesep = "",
    escape = FALSE,
    digits = 3,
    col.names = c("Coeficiente","Estimativa", "EP" , "Estatística t", "p-valor"),
    caption = "Modelo de regressão linear múltipla completo, aplicado para todas as variáveis."
    ) %>%
  kableExtra::kable_styling(
      position = "center",
      latex_options = c("striped", "repeat_header"),
      stripe_color = "gray!15")



```

Nota-se que duas variáveis, x7 e x10, apresentam estimadores no modelo como `NA`. Isso contece porque há um elevado grau de correlação entre elas, o que atrapalha na estimação dos parâmetros de ambas com relação a variável resposta $y$.

Ignorando por enquanto esse fato, podemos fazer uma análise prévia dos resíduos desse modelo e averiguar se há alguma inconsistência. Para tal, faz-se uma análise gráfica dos e, posteriormente, um teste de normalidade dos resíduos e de autocorrelação entre os resíduos, além de um teste de heterocedasticidade do modelo. 

Analisando os gráficos a seguir, nota-se do primeiro gráfico que a linha está aproximadamente horizontal. Logo, tem-se linearidade no modelo. No segundo gráfico vê-se que os resíduos aparentam ter distribuição normal. Já no terceiro gráfico, aparenta-se haver homocedasticidade, pois os resíduos estão dispersos como retângulo. Por fim, no quarto gráfico, para observar outliers e pontos influentes, não aparenta possuir resíduos outliers pois os resíduos estão entre -3 e +3.

```{r, fig.align='center', fig.width=6.5, fig.height=6.5}

#Analisando os resíduos do modelo
par(mfrow=c(2,2))
plot(modelo_reg_multi) 
## primeiro gráfico com linha apróx. horizontal - tem linearidade no modelo
## resíduos talvez apróx. com dist. normais no segundo gráfico
## terceiro gráfico observando a homocedasticidade - existe homocedasticidade, pois estão dispersos como retângulo, não triângulo
## quarto gráfico para observar outliers e pontos influentes - resíduos entre -3 e +3 corrteo, além de não aparentar outliers
```


Considerando os testes aplicados, nota-se que não há outliers nos resíduos, não rejeita-se normalidade dos resíduos, não há evidências de que há heterocedasticidade e não rejeita-se a independência dos resíduos, logo, eles não apresentam autocorrelação.

```{r}
## Outliers nos resíduos
summary(rstandard(modelo_reg_multi)) %>% #não tem valores fugindo de -3 e +3, então não tem outliers
  tidy() %>%
  knitr::kable(
    format = "latex",
    align = c("c"),
    booktabs = TRUE,
    longtable = TRUE,
    linesep = "",
    escape = FALSE,
    digits = 3,
    caption = "Medidas estatísticas dos resíduos do modelo completo."
    ) %>%
  kableExtra::kable_styling(
      position = "center",
      latex_options = c("striped", "repeat_header"),
      stripe_color = "gray!15")
```

```{r}
bind_rows(
  ## Teste de normalidade do resíduos Shapiro-Wilk
  shapiro.test(modelo_reg_multi$residuals) %>% tidy(), 
  #Não rejeita normalidade dos resíduos (H0)
  
  ## Perform breush-pagan test for hetereocedascity
  ## Teste de heterocedasticidade breush-pagan para o modelo - só funciona se os resíduos tiverem dist. normal
  (bptest(modelo_reg_multi) %>% tidy())[, c(1, 2, 4)],
  #Não rejeita H0 de que não há heterocedasticidade (há homocedasticidade)
                         # Logo, não há evidências de que há heterocedasticidade
  
  ## Perform Durbin-Watson test for Independence
  ## Teste Durbin-Watson para a presença de autocorrelação nos resíduos (se são indep.) - só funciona se os resíduos tiverem dist. normal 
  (durbinWatsonTest(modelo_reg_multi) %>% tidy())[,c(1, 2, 4)]
) %>%
  #Não rejeita H0 de que não há autocorrelação
                                   # Logo, os resíduos aparentam ser independentes
  dplyr::select(method, everything()) %>%
  knitr::kable(
    format = "latex",
    align = c("lcc"),
    booktabs = TRUE,
    longtable = TRUE,
    linesep = "",
    escape = FALSE,
    digits = 3,
    col.names = c("Teste","Estatística de teste","p-valor"),
    caption = "Testes de hipótese para normalidade, heteroscedasticidade e independência."
    ) %>%
  kableExtra::kable_styling(
      position = "center",
      latex_options = c("striped", "repeat_header"),
      stripe_color = "gray!15")

```


Já que os resíduos aparentam seguir as características esperadas, vamos avaliar se há multicolinearidade no modelo, uma vez que haviam fortes correlações entre as variáveis.

```{r, fig.height = 5, fig.align='center', fig.cap = "Distribuição dois a dois das variáveis disponíveis.", include = FALSE}
# ## Analisando a ausência de Multicolinearidade no modelo
# pairs.panels(dados_qualidade_vinho, gap=0.2) #Multicolinearidade se r > 0.9 ou 0.8

```

{{< pagebreak >}}

## a) Proponha algum método para resolver o problema da multicolinearidade no conjunto de dados

Nota-se do tópico anterior que x7 e x10 são fortemente correlacionadas com outras variáveis, o que impossibilita de se estimar os parâmetros dessas variáveis para o modelo. Logo, podemos retirá-las e analisar novamente o modelo, avaliando se ainda há multicolinearidade nele por meio da medida VIF, calculada para cada variável.

```{r}
# modelo ajustado sem x7 e x10
modelo_reg_multi2 <- lm(y~x1+x2+x3+x4+x5+x6+x8+x9, data=dados_qualidade_vinho)

summary(modelo_reg_multi2)%>% 
  tidy() %>%
  knitr::kable(
    format = "latex",
    align = c("lcccc"),
    booktabs = TRUE,
    longtable = TRUE,
    linesep = "",
    escape = FALSE,
    digits = 3,
    col.names = c("Coeficiente","Estimativa", "EP" , "Estatística t", "p-valor"),
    caption = "Modelo de regressão linear sem x7 e x10"
    ) %>%
  kableExtra::kable_styling(
      position = "center",
      latex_options = c("striped", "repeat_header"),
      stripe_color = "gray!15")

#multicolinearidade
vif(modelo_reg_multi2) %>%
  tidy() %>%
  knitr::kable(
    format = "latex",
    align = c("c"),
    booktabs = TRUE,
    longtable = TRUE,
    linesep = "",
    escape = FALSE,
    digits = 3,
    col.names = c("Variável", "VIF"),
    caption = "VIF para modelo sem x7 e x10"
    ) %>%
  kableExtra::kable_styling(
      position = "center",
      latex_options = c("striped", "repeat_header"),
      stripe_color = "gray!15") # Multicolinearidade se VIF > 10 (severa) e > 5 (moderada)
                       ## Mostra que mesmo tirando x7 e x10 que tinham correlação perfeita
                       ## Ainda há multicolinearidade em x4, x5, x6 e x9
```

Analisando os VIFs, nota-se que apesar de se retirar x7 e x10 ainda há multicolinearidade no modelo. Poderíamos agora testar três métodos para se retirar a multicolinearidade, sem precisar retirar as variáveis: centrar, escalonar ou padronizar empiricamente as variáveis preditoras. No entanto, após testar os três métodos, percebeu-se que não mudou os índices de multicolinearidade. Logo, esses métodos não foram eficazes. Portanto, testaremos a remoção da variável de maior VIF, x4. 

```{r}
# modelo ajustado sem x7 e x10
modelo_reg_multi2 <- lm(y~x1+x2+x3+x5+x6+x8+x9, data=dados_qualidade_vinho)

summary(modelo_reg_multi2)%>% 
  tidy() %>%
  knitr::kable(
    format = "latex",
    align = c("lcccc"),
    booktabs = TRUE,
    longtable = TRUE,
    linesep = "",
    escape = FALSE,
    digits = 3,
    col.names = c("Coeficiente","Estimativa", "EP" , "Estatística t", "p-valor"),
    caption = "Modelo de regressão linear sem x4, x7 e x10"
    ) %>%
  kableExtra::kable_styling(
      position = "center",
      latex_options = c("striped", "repeat_header"),
      stripe_color = "gray!15")

#multicolinearidade
vif(modelo_reg_multi2) %>%
  tidy() %>%
  knitr::kable(
    format = "latex",
    align = c("c"),
    booktabs = TRUE,
    longtable = TRUE,
    linesep = "",
    escape = FALSE,
    digits = 3,
    col.names = c("Variável", "VIF"),
    caption = "VIF para modelo sem x4, x7 e x10"
    ) %>%
  kableExtra::kable_styling(
      position = "center",
      latex_options = c("striped", "repeat_header"),
      stripe_color = "gray!15")
```

Ainda notando-se alta multicolinearidade, podemos eliminar a variável x5 de maior VIF, ou seja, maior grau de correlação com as demais, e analisar o que acontece.

```{r}
#modelo ajustado sem as outras variáveis que estão apontando multicolinearidade 
modelo_reg_multi2 <- lm(y~x1+x2+x3+x6+x8+x9, data=dados_qualidade_vinho)

summary(modelo_reg_multi2)%>% 
  tidy() %>%
  knitr::kable(
    format = "latex",
    align = c("lcccc"),
    booktabs = TRUE,
    longtable = TRUE,
    linesep = "",
    escape = FALSE,
    digits = 3,
    col.names = c("Coeficiente","Estimativa", "EP" , "Estatística t", "p-valor"),
    caption = "Modelo de regressão linear sem x4, x5, x7 e x10"
    ) %>%
  kableExtra::kable_styling(
      position = "center",
      latex_options = c("striped", "repeat_header"),
      stripe_color = "gray!15")


vif(modelo_reg_multi2) %>%
  tidy() %>%
  knitr::kable(
    format = "latex",
    align = c("c"),
    booktabs = TRUE,
    longtable = TRUE,
    linesep = "",
    escape = FALSE,
    digits = 3,
    col.names = c("Variável", "VIF"),
    caption = "VIF para modelo sem x4, x5, x7 e x10"
    ) %>%
  kableExtra::kable_styling(
      position = "center",
      latex_options = c("striped", "repeat_header"),
      stripe_color = "gray!15") #não há mais multicolinearidade

```

Agora sim foi possível eliminar a multicolinearidade e seguir para uma seleção do melhor modelo final. 


## b) Usando algum método de seleção de variáveis, obtenha o modelo final para o conjunto de dados

Considerando os métodos de seleção de variáveis Forward, Bacward e Stepwise, pode-se selecionar o melhor modelo com base no critério de AIC.

Pelo método de seleção de variáveis *stepwise backward*, obtém-se o melhor modelo, com menor AIC (Critério de Informação de Akaike), no formato $\hat{y}_i = \hat{\beta}_0 + \hat{\beta}_1 \, x_{1i} + \hat{\beta}_2 \,x_{2i} + \hat{\beta}_3 \, x_{3i} + \hat{\beta}_9\,x_{9i}$, excluindo-se as vaiáveis x4, x5, x6, x7, x8, x10 do modelo.

```{r stepwise, include= FALSE}
#modelo_forward <- stepAIC(modelo_reg_multi2, direction = "forward")

#modelo_backward <- stepAIC(modelo_reg_multi2, direction = "backward") 
##seleciona o melhor modelo como y ~ x1 + x2 + x3 + x9

modelo_stepwise <- stepAIC(modelo_reg_multi2, direction = "both") 
##seleciona o melhor modelo como y ~ x1 + x2 + x3 + x9

```

```{r}

modelo_final <- lm(y~ x1 + x2 + x3 + x9, data=dados_qualidade_vinho)

summary(modelo_final)%>% 
  tidy() %>%
  knitr::kable(
    format = "latex",
    align = c("lcccc"),
    booktabs = TRUE,
    longtable = TRUE,
    linesep = "",
    escape = FALSE,
    digits = 3,
    col.names = c("Coeficiente","Estimativa", "EP" , "Estatística t", "p-valor"),
    caption = "Modelo de regressão linear com x1, x2, x3 e x9"
    ) %>%
  kableExtra::kable_styling(
      position = "center",
      latex_options = c("striped", "repeat_header"),
      stripe_color = "gray!15")

vif(modelo_final) %>%
  tidy() %>%
  knitr::kable(
    format = "latex",
    align = c("c"),
    booktabs = TRUE,
    longtable = TRUE,
    linesep = "",
    escape = FALSE,
    digits = 3,
    col.names = c("Variável", "VIF"),
    caption = "VIF para modelo linear com x1, x2, x3 e x9"
    ) %>%
  kableExtra::kable_styling(
      position = "center",
      latex_options = c("striped", "repeat_header"),
      stripe_color = "gray!15") #não há mais multicolinearidade
```


Com isso, seleciona-se o seguinte modelo final, com todas as variáveis significativas e sem multicolinearidade:

\begin{align}
  y_i = \beta_0 + \beta_1 \, x_{i1} + \beta_2 \, x_{i2} + \beta_3 \, x_{i3}\ + \beta_4 \, x_{i9} + \varepsilon_i, \quad i = 1, 2, \dots, 32.
\end{align}


## c) Apresente a tabela de Análise de Variância para testar a significância global dos coeficientes do modelo final. Apresente as hipóteses de teste e conclua.

Para testar as hipóteses

\begin{align}
  H_0: \beta_j = 0, \quad H_a: \beta_j \neq 0
\end{align}

monta-se a seguinte tabela de análise de variância:

```{r}
anova(modelo_final)%>%
  tidy() %>%
  knitr::kable(
    format = "latex",
    align = c("lcccc"),
    booktabs = TRUE,
    longtable = TRUE,
    linesep = "",
    escape = FALSE,
    digits = 3,
    col.names = c("Fonte de Var.","g.l.", "SQ" , "QM", "F", "p-valor"),
    caption = "Tabela ANOVA para o modelo linear com x1, x2, x2, x3 e x9"
    ) %>%
  kableExtra::kable_styling(
      position = "center",
      latex_options = c("striped", "repeat_header"),
      stripe_color = "gray!15")

```

Pode-se concluir que para um nível de significância de 0.05, a variável x1 não tem seu coeficiente significativamente diferente de zero para o modelo, o que significa que pode-se considerar a sua remoção. Isto é, essa variável não contribui de forma estatisticamente significativa para a explicação da variável $y$. Dessa forma, analisa-se novamente a ANOVA.

Nota-se ainda que, ao retirar x1, x3 também passa a não contribuir de forma estatisticamente significativa para a explicação da variável $y$, apresentando coeficiente significativamente igual a 0 para um nível de significância de 0,05. Logo, retira-se essa variável também.


```{r}
modelo_final <- lm(y~ x2 + x3 + x9, data=dados_qualidade_vinho)

summary(modelo_final)%>% 
  tidy() %>%
  knitr::kable(
    format = "latex",
    align = c("lcccc"),
    booktabs = TRUE,
    longtable = TRUE,
    linesep = "",
    escape = FALSE,
    digits = 3,
    col.names = c("Coeficiente","Estimativa", "EP" , "Estatística t", "p-valor"),
    caption = "Modelo de regressão linear com x2, x3 e x9"
    ) %>%
  kableExtra::kable_styling(
      position = "center",
      latex_options = c("striped", "repeat_header"),
      stripe_color = "gray!15")

anova(modelo_final)%>%
  tidy() %>%
  knitr::kable(
    format = "latex",
    align = c("lcccc"),
    booktabs = TRUE,
    longtable = TRUE,
    linesep = "",
    escape = FALSE,
    digits = 3,
    col.names = c("Fonte de Var.","g.l.", "SQ" , "QM", "F", "p-valor"),
    caption = "Tabela ANOVA para o modelo linear com x2, x3 e x9"
    ) %>%
  kableExtra::kable_styling(
      position = "center",
      latex_options = c("striped", "repeat_header"),
      stripe_color = "gray!15")
```


Por fim, para $\alpha = 0.05$, temos o modelo final para esses dados, que é

```{=tex}
\begin{align}
  y_i = \beta_0 + \beta_1 \, x_{i2} + \beta_2 \, x_{i9} + \varepsilon_i, \quad i = 1, 2, \dots, 32,
\end{align}
```

obtido considerando os resultados das tabelas a seguir.

```{r}
modelo_final <- lm(y~ x2 + x9, data=dados_qualidade_vinho)

summary(modelo_final)%>% 
  tidy() %>%
  knitr::kable(
    format = "latex",
    align = c("lcccc"),
    booktabs = TRUE,
    longtable = TRUE,
    linesep = "",
    escape = FALSE,
    digits = 3,
    col.names = c("Coeficiente","Estimativa", "EP" , "Estatística t", "p-valor"),
    caption = "Modelo de regressão linear com x2 e x9"
    ) %>%
  kableExtra::kable_styling(
      position = "center",
      latex_options = c("striped", "repeat_header"),
      stripe_color = "gray!15")

anova(modelo_final)%>%
  tidy() %>%
  knitr::kable(
    format = "latex",
    align = c("lcccc"),
    booktabs = TRUE,
    longtable = TRUE,
    linesep = "",
    escape = FALSE,
    digits = 3,
    col.names = c("Fonte de Var.","g.l.", "SQ" , "QM", "F", "p-valor"),
    caption = "Tabela ANOVA para o modelo linear com x2 e x9"
    ) %>%
  kableExtra::kable_styling(
      position = "center",
      latex_options = c("striped", "repeat_header"),
      stripe_color = "gray!15")
```



## d) Com base no modelo obtido no item anterior, faça uma análise de resíduos e conclua.

Para uma análise de resíduos, fazemos uma análise gráfica e, posteriormente, teste de normalidade, de autocorrelação e de heterocedasticidade do dos resíduos.

Analisando os gráficos, nota-se que estão aproximadamente distribuídos em torno de zero, que os resíduos apresentam ter distribuição normal, que aparenta-se haver homocedasticidade e que não aparenta possuir resíduos outliers.

```{r, fig.align='center', fig.width=6.5, fig.height=6.5}

#Analisando os resíduos do modelo
par(mfrow=c(2,2))
plot(modelo_final)

```

Confirmando as informações gráficas através dos testes, para um nível de significância de 0,05, nota-se que não há outliers nos  resíduos, não rejeita-se normalidade dos resíduos, não há evidências de que há heterocedasticidade e não rejeita-se a independência dos resíduos, logo, eles não apresentam autocorrelação.

```{r}
#Analisando os resíduos do modelo
 
## primeiro gráfico com linha apróx. horizontal - tem linearidade no modelo
## resíduos talvez apróx. com dist. normais no segundo gráfico
## terceiro gráfico observando a homocedasticidade - existe homocedasticidade, pois estão dispersos como retângulo, não triângulo
## quarto gráfico para observar outliers e pontos influentes - resíduos entre -3 e +3 corrteo, além de não aparentar outliers

bind_rows(
## Teste de normalidade do resíduos Shapiro-Wilk 
shapiro.test(modelo_final$residuals) %>% tidy(), #Não rejeita normalidade dos resíduos (H0)

## Teste de heterocedasticidade breush-pagan para o modelo - só funciona se os resíduos tiverem dist. normal
(bptest(modelo_final) %>% tidy())[, c(1, 2, 4)], #Não rejeita H0 de que não há heterocedasticidade (há homocedasticidade)
                         # Logo, não há evidências de que há heterocedasticidade

## Teste Durbin-Watson para a presença de autocorrelação nos resíduos (se são indep.) - só funciona se os resíduos tiverem dist. normal 
(durbinWatsonTest(modelo_final) %>% tidy())[,c(1, 2, 4)] #Não rejeita H0 de que não há autocorrelação
                                   # Logo, os resíduos aparentam ser independentes
) %>%
  dplyr::select(method, everything()) %>%
  knitr::kable(
    format = "latex",
    align = c("lcc"),
    booktabs = TRUE,
    longtable = TRUE,
    linesep = "",
    escape = FALSE,
    digits = 3,
    col.names = c("Teste","Estatística de teste","p-valor"),
    caption = "Testes de hipótese para normalidade, heteroscedasticidade e independência."
    ) %>%
  kableExtra::kable_styling(
      position = "center",
      latex_options = c("striped", "repeat_header"),
      stripe_color = "gray!15")

```

```{r}
## Outliers nos resíduos
summary(rstandard(modelo_final)) %>% 
  tidy() %>%
  knitr::kable(
    format = "latex",
    align = c("lcc"),
    booktabs = TRUE,
    longtable = TRUE,
    linesep = "",
    escape = FALSE,
    digits = 3,
    caption = "Medidas descritivas dos resíduos padronizados."
    ) %>%
  kableExtra::kable_styling(
      position = "center",
      latex_options = c("striped", "repeat_header"),
      stripe_color = "gray!15") #não tem valores fugindo de -3 e +3, então não tem outliers
```
Portanto, como os resíduos estão de acordo com as suposições esperadas, pode-se concluir que o modelo escolhido no item anterior como modelo final, com a relação entre $y$, x2 e x9, está adequado. Fazendo uma análise desse modelo de regressão linear múltipla, poderia-se afirmar que para cada 1 unidade a mais de PH do vinho, a qualidade do vinho aumentaria, em média, 4.5 (t= 2.291; p-valor = 0.0294). Já para cada aumento de um grau de ionização das antocianinas (em porcentagem), a qualidade do vinho aumentaria, em média, 0.19 (t= 4.695; p-valor = 5.91e-05).


{{< pagebreak >}}

# Questão 2

Uma equipe de pesquisadores de saúde mental deseja comparar três métodos de tratamento da depressão grave (A, B e C=referência). Eles também gostariam de estudara relação entre idade e eficácia do tratamento, bem como a interação (se houver) entre idade e tratamento. Cada elemento da amostra aleatória simples de 36 pacientes, foi selecionado aleatoriamente para receber o tratamento A, B ou C. Os dados obtidos podem ser encontrados no ficheiro `Q02-data.txt`. A variável dependente $y$ é a eficácia do tratamento; as variáveis independentes são: a idade do paciente no aniversário mais próximo e o tipo de tratamento administrado (use 1% de significância durantes as análises).

Uma amostra dos dados é exibida na tabela a seguir:

```{r dados-q2}

dados <- read.table("dados lista 2/Q02_data.txt", header=T)

head(dados)%>%
  knitr::kable(
    format = "latex",
    align = c("c"),
    booktabs = TRUE,
    longtable = TRUE,
    linesep = "",
    escape = FALSE,
    digits = 2
    ) %>%
  kableExtra::kable_styling(
      position = "center",
      latex_options = c("striped", "repeat_header"),
      stripe_color = "gray!15")

```

Um histograma da variável resposta é exibido a seguir, sugerindo assimetria na sua distribuição.

```{r histograma-q2,fig.align='center', fig.cap = "Histograma da variável resposta", fig.height = 2, fig.width = 3.5}
dados %>%
  ggplot(aes(eficacia))+
  geom_histogram(color = "black", fill = "gray", bins = 10)+
  scale_y_continuous(limits = c(0, 9),
                     expand = expansion(mult = 0, add = 0))+
  labs(x = "Eficácia", y = "")+
  theme_bw()+
  theme(axis.ticks = element_blank())
```

No entanto, se montamos um histograma da variável resposta para cada valor de tratamento, vemos que há uma discrepência na sua distribuição. O tratamento A está bem concentrando em eficácias mais altas, enquanto o B está mais concentrado ao centro da métrica de eficácia e o C está amplamente distribuído.

```{r histograma-q2-facet,fig.align='center', fig.cap = "Histograma da variável resposta segregado por tratamento", fig.height = 2.5}
dados %>%
  ggplot(aes(eficacia, fill = tratamento))+
  geom_histogram(bins = 10, color = "black")+
  scale_y_continuous(limits = c(0, 5),
                     expand = expansion(mult = 0, add = 0))+
  labs(x = "Eficácia", y = "", fill = "Tratamento")+
  theme_bw()+
  theme(axis.ticks = element_blank())+
  facet_wrap(~tratamento)
```

## a) Ajuste um modelo de regressão linear e interprete os resultados obtidos

Inicialmente, consideremos apenas um gráfico de dispersão entre a variável resposta e a única variável numérica, Idade. É possível notar uma relação que pode ou não ser linear, mas também há indícios de heteroscedasticidade. As demais variáveis são dicotômicas, então não há necessidade de se montar dispersões para elas.

Além disso, se segregamos a dispersão por grupos de tratamento, notamos que pode ser preferível um modelo que considere comportamentos de cada grupo separadamente.

```{r scatter-variaveis, fig.align='center', fig.cap = "Gráficos de dispersão geral e segregado por tratamento", fig.height = 2.5}
geral <- ggplot(dados, aes(x = idade, y = eficacia))+
  geom_point(shape = 15, size = 2, alpha = .75)+
  geom_smooth(method = "lm", se = FALSE)+
  labs(y = "Eficácia", x = "Idade")+
  theme_bw()+
  theme(axis.ticks = element_blank())

trat <- ggplot(dados, aes(x = idade, y = eficacia, color = tratamento))+
  geom_point(shape = 15, size = 2, alpha = .75)+
  labs(y = "Eficácia", x = "Idade")+
  theme_bw()+
  theme(axis.ticks = element_blank(),
        legend.position = "none")

plot_grid(geral, trat)
```

Temos um potencial modelo de regressão linear que pode ou não conter interações entre as variáveis, o qual pode ser expresso em sua forma saturada, em que $X_1$ é a variável idade e $X_2$ a variável tratamento

```{=tex}
\begin{align}
  y_i = \beta_0 + \beta_1 \, x_{1i} + \beta_2 \, x_{2i} + \beta_3 \, x_{1i}\, x_{2i} + \varepsilon_i, \quad i = 1, 2, \dots, n
\end{align}
```
ou, de forma análoga, desmembrando $X_2$ em variáveis *dummy* $X_A$ e $X_B$, indicadores da presença do tratamento $A$ e $B$, ambas assumindo valor $0$ quando se trata do tratamento $C$

```{=tex}
\begin{align}
  y_i = \beta_0 + \beta_1 \, x_{1i} + \beta_2 \, x_{Ai} + \beta_3 \, x_{Bi} + \beta_4 \, x_{1i} \, x_{Ai} + \beta_5 \, x_{1i} \, x_{Bi} + \varepsilon_i. \label{modelo_dummy}
\end{align}
```
Se simplesmente ajustamos um modelo de regressão linear -- sem os termos de interação -- utilizando (\ref{modelo_dummy}) como referência na função `lm()`, obtemos os seguintes resultados:

```{r ajuste-modelo2}
#da encoding à variavel tratamento
dados_dummy <- dados %>%
  mutate(A = if_else(tratamento == "A", 1, 0),
         B = if_else(tratamento == "B", 1, 0)) %>%
  dplyr::select(-tratamento)

#monta fit aditivo do modelo
fit_depressao <- lm(eficacia ~ (.), data = dados_dummy)

#tabela do modelo
fit_depressao %>%
  summary() %>% 
  tidy() %>%
  knitr::kable(
    format = "latex",
    align = c("lcccc"),
    booktabs = TRUE,
    longtable = TRUE,
    linesep = "",
    escape = FALSE,
    digits = 3,
    col.names = c("Coeficiente","Estimativa", "EP" , "Estatística t", "p-valor"),
    caption = "Modelo de regressão linear para tratamentos sem interação com idade sobre eficácia"
    ) %>%
  kableExtra::kable_styling(
      position = "center",
      latex_options = c("striped", "repeat_header"),
      stripe_color = "gray!15")
```

Ou seja, se considerarmos independentemente idade, tratamento A e tratamento B, podemos considerar que:

-   Há uma linha de base na eficácia de aproximadamente 22.3, i.e. sob o tratamento C;
-   A eficácia base para o tratamento A é de 32.3;
-   A eficácia base para o tratamento B é de 22.75 -- mas poderíamos desconsiderar este coeficiente, se nos guiarmos pelo p-valor;
-   Cada ano a mais de vida incrementa a eficácia em 0.644.

É possível considerar que um tamanho de amostra pequeno tenha grande influência sobre a significância de $H_0: \beta_3 = 0$ do modelo. No entanto, trata-se de um fenômeno para o qual o tratamento pode estar estreitamente associado à idade, caso em que teríamos que considerar o modelo (\ref{modelo_dummy}) por completo.

## b) Obtenha a tabela ANOVA para o modelo obtido no item (a) e interprete os resultados

Se montarmos uma tabela de Análise de Variância para o modelo de regressão linear ajustado, obtemos os resultados a seguir:

```{r anova-fit-depressao}
anova(fit_depressao) %>%
  tidy() %>%
  knitr::kable(
    format = "latex",
    align = c("lcccc"),
    booktabs = TRUE,
    longtable = TRUE,
    linesep = "",
    escape = FALSE,
    digits = 3,
    col.names = c("Fonte de Var.","g.l.", "SQ" , "QM", "F", "p-valor"),
    caption = "Tabela ANOVA para o modelo linear sem interações"
    ) %>%
  kableExtra::kable_styling(
      position = "center",
      latex_options = c("striped", "repeat_header"),
      stripe_color = "gray!15")
```

Nota-se que a maioria da variância explicada pelo modelo está associada à variável idade, enquanto a soma de quadrados das variáveis de tratamento juntas não superam a soma de quadrados dos resíduos.

Se conjugarmos os resultados deste item com os do item a) vemos que isoladamente apenas idade, e interessantemente apenas o tratamento A, parecem ser variáveis que realmente contribuem para a explicação do fenômeno.

## c) Considere a possibilidade de incluir a interação entre as varáveis independentes

### i) Lista de todos os submodelos possíveis

A partir do modelo (\ref{modelo_dummy}), construimos todos os possíveis submodelos. Considerando que temos três covariáveis e dois termos de interação, temos $\sum\limits_{n = 1}^5\binom{6}{n} = 62$ modelos

```{=tex}
\begin{enumerate}
  \item $y_i = \beta_0 + \varepsilon_i$
  \item $y_i = \beta_1 \, x_{1i} + \varepsilon_i$
  \item $y_i = \beta_2 \, x_{Ai} + \varepsilon_i$
  \item $y_i = \beta_3 \, x_{Bi} + \varepsilon_i$
  \item $y_i = \beta_4 \, x_{1i} \, x_{Ai} + \varepsilon_i$
  \item $y_i = \beta_5 \, x_{1i} \, x_{Bi} + \varepsilon_i$
  
 
  \item $y_i = \beta_0 + \beta_1 \, x_{1i} + \varepsilon_i$
  \item $y_i = \beta_0 + \beta_2 \, x_{Ai} + \varepsilon_i$
  \item $y_i = \beta_0 + \beta_3 \, x_{Bi} + \varepsilon_i$
  \item $y_i = \beta_0 + \beta_4 \, x_{1i} \, x_{Ai} + \varepsilon_i$
  \item $y_i = \beta_0 + \beta_5 \, x_{1i} \, x_{Bi} + \varepsilon_i$
  \item $y_i = \beta_1 \, x_{1i} + \beta_2 \, x_{Ai} + \varepsilon_i$
  \item $y_i = \beta_1 \, x_{1i} + \beta_3 \, x_{Bi} + \varepsilon_i$
  \item $y_i = \beta_1 \, x_{1i} + \beta_4 \, x_{1i} \, x_{Ai} + \varepsilon_i$
  \item $y_i =  \beta_1 \, x_{1i} + \beta_5 \, x_{1i} \, x_{Bi} + \varepsilon_i$
  \item $y_i = \beta_2 \, x_{Ai} + \beta_3 \, x_{Bi}+ \varepsilon_i$
  \item $y_i = \beta_2 \, x_{Ai} + \beta_4 \, x_{1i} \, x_{Ai} + \varepsilon_i$
  \item $y_i = \beta_2 \, x_{Ai} + \beta_5 \, x_{1i} \, x_{Bi} + \varepsilon_i$
  \item $y_i = \beta_3 \, x_{Bi} + \beta_4 \, x_{1i} \, x_{Ai} + \varepsilon_i$
  \item $y_i = \beta_3 \, x_{Bi} + \beta_5 \, x_{1i} \, x_{Bi} + \varepsilon_i$
  \item $y_i = \beta_4 \, x_{1i} \, x_{Ai} + \beta_5 \, x_{1i} \, x_{Bi} + \varepsilon_i$
  
  

  \item $y_i = \beta_0 + \beta_1 \, x_{1i} + \beta_2 \, x_{Ai} + \varepsilon_i$
  \item $y_i = \beta_0 + \beta_1 \, x_{1i} + \beta_3 \, x_{Bi} + \varepsilon_i$
  \item $y_i = \beta_0 + \beta_1 \, x_{1i} + \beta_4 \, x_{1i} \, x_{Ai} + \varepsilon_i$
  \item $y_i = \beta_0 + \beta_1 \, x_{1i} + \beta_5 \, x_{1i} \, x_{Bi} + \varepsilon_i$
  \item $y_i = \beta_0 + \beta_2 \, x_{Ai} + \beta_3 \, x_{Bi} + \varepsilon_i$
  \item $y_i = \beta_0 + \beta_2 \, x_{Ai} + \beta_4 \, x_{1i} \, x_{Ai} +  \varepsilon_i$
  \item $y_i = \beta_0 + \beta_2 \, x_{Ai} + \beta_5 \, x_{1i} \, x_{Bi} + \varepsilon_i$
  \item $y_i = \beta_0 + \beta_3 \, x_{Bi} + \beta_4 \, x_{1i} \, x_{Ai} +  \varepsilon_i$
  \item $y_i = \beta_0 + \beta_3 \, x_{Bi} + \beta_5 \, x_{1i} \, x_{Bi} + \varepsilon_i$
  \item $y_i = \beta_0 + \beta_4 \, x_{1i} \, x_{Ai} + \beta_5 \, x_{1i} \, x_{Bi} + \varepsilon_i$
  \item $y_i = \beta_1 \, x_{1i} + \beta_2 \, x_{Ai} + \beta_3 \, x_{Bi} + \varepsilon_i$
  \item $y_i = \beta_1 \, x_{1i} + \beta_2 \, x_{Ai} + \beta_4 \, x_{1i} \, x_{Ai} + \varepsilon_i$
  \item $y_i = \beta_1 \, x_{1i} + \beta_2 \, x_{Ai} + \beta_5 \, x_{1i} \, x_{Bi} + \varepsilon_i$
  \item $y_i = \beta_1 \, x_{1i} + \beta_3 \, x_{Bi} + \beta_4 \, x_{1i} \, x_{Ai} + \varepsilon_i$
  \item $y_i = \beta_1 \, x_{1i} + \beta_3 \, x_{Bi} + \beta_5 \, x_{1i} \, x_{Bi} + \varepsilon_i$
  \item $y_i = \beta_1 \, x_{1i} + \beta_4 \, x_{1i} \, x_{Ai} + \beta_5 \, x_{1i} \, x_{Bi} + \varepsilon_i$
  \item $y_i = \beta_2 \, x_{Ai} + \beta_3 \, x_{Bi} + \beta_4 \, x_{1i} \, x_{Ai} + \varepsilon_i$
  \item $y_i = \beta_2 \, x_{Ai} + \beta_3 \, x_{Bi} + \beta_5 \, x_{1i} \, x_{Bi} + \varepsilon_i$
  \item $y_i = \beta_2 \, x_{Ai} + \beta_4 \, x_{1i} \, x_{Ai} + \beta_5 \, x_{1i} \, x_{Bi} + \varepsilon_i$
  \item $y_i = \beta_3 \, x_{Bi} + \beta_4 \, x_{1i} \, x_{Ai} + \beta_5 \, x_{1i} \, x_{Bi} + \varepsilon_i$
  

 
  \item $y_i = \beta_0 + \beta_1 \, x_{1i} + \beta_2 \, x_{Ai} + \beta_3 \, x_{Bi} + \varepsilon_i$
  \item $y_i = \beta_0 + \beta_1 \, x_{1i} + \beta_2 \, x_{Ai} + \beta_4 \, x_{1i} \, x_{Ai} + \varepsilon_i$
  \item $y_i = \beta_0 + \beta_1 \, x_{1i} + \beta_2 + \beta_5 \, x_{1i} \, x_{Bi} + \varepsilon_i$
  \item $y_i = \beta_0 + \beta_1 \, x_{1i} + \beta_3 \, x_{Bi} + \beta_4 \, x_{1i} \, x_{Ai} + \varepsilon_i$
  \item $y_i = \beta_0 + \beta_1 \, x_{1i} + \beta_3 \, x_{Bi} + \beta_5 \, x_{1i} \, x_{Bi} + \varepsilon_i$
  \item $y_i = \beta_0 + \beta_1 \, x_{1i} + \beta_4 \, x_{1i} \, x_{Ai} + \beta_5 \, x_{1i} \, x_{Bi} + \varepsilon_i$
  
  \item $y_i = \beta_0 + \beta_2 \, x_{Ai} + \beta_3 \, x_{Bi} + \beta_4 \, x_{1i} \, x_{Ai} + \varepsilon_i$
  \item $y_i = \beta_0 + \beta_2 \, x_{Ai} + \beta_3 \, x_{Bi} + \beta_5 \, x_{1i} \, x_{Bi} + \varepsilon_i$
  \item $y_i = \beta_0 + \beta_2 \, x_{Ai} + \beta_4 \, x_{1i} \, x_{Ai} + \beta_5 \, x_{1i} \, x_{Bi} + \varepsilon_i$
  \item $y_i = \beta_0 + \beta_3 \, x_{Bi} + \beta_4 \, x_{1i} \, x_{Ai} + \beta_5 \, x_{1i} \, x_{Bi} + \varepsilon_i$
  
  \item $y_i = \beta_1 \, x_{1i} + \beta_2 \, x_{Ai} + \beta_3 \, x_{Bi} + \beta_4 \, x_{1i} \, x_{Ai} + \varepsilon_i$
  \item $y_i = \beta_1 \, x_{1i} + \beta_2 \, x_{Ai} + \beta_3 \, x_{Bi} + \beta_5 \, x_{1i} \, x_{Bi} + \varepsilon_i$
  \item $y_i = \beta_1 \, x_{1i} + \beta_2 \, x_{Ai} + \beta_4 \, x_{1i} \, x_{Ai} + \beta_5 \, x_{1i} \, x_{Bi} + \varepsilon_i$
  \item $y_i = \beta_1 \, x_{1i} + \beta_3 \, x_{Bi} + \beta_4 \, x_{1i} \, x_{Ai} + \beta_5 \, x_{1i} \, x_{Bi} + \varepsilon_i$
  
  \item $y_i = \beta_2 \, x_{Ai} + \beta_3 \, x_{Bi} + \beta_4 \, x_{1i} \, x_{Ai} + \beta_5 \, x_{1i} \, x_{Bi} + \varepsilon_i$
  
  \item $y_i = \beta_1 \, x_{1i} + \beta_2 \, x_{Ai} + \beta_3 \, x_{Bi} + \beta_4 \, x_{1i} \, x_{Ai} + \beta_5 \, x_{1i} \, x_{Bi} + \varepsilon_i$
  
  \item $y_i = \beta_0 + \beta_2 \, x_{Ai} + \beta_3 \, x_{Bi} + \beta_4 \, x_{1i} \, x_{Ai} + \beta_5 \, x_{1i} \, x_{Bi} + \varepsilon_i$
  \item $y_i = \beta_0 + \beta_1 \, x_{1i} + \beta_3 \, x_{Bi} + \beta_4 \, x_{1i} \, x_{Ai} + \beta_5 \, x_{1i} \, x_{Bi} + \varepsilon_i$
  \item $y_i = \beta_0 + \beta_1 \, x_{1i} + \beta_2 \, x_{Ai} + \beta_4 \, x_{1i} \, x_{Ai} + \beta_5 \, x_{1i} \, x_{Bi} + \varepsilon_i$
  \item $y_i = \beta_0 + \beta_1 \, x_{1i} + \beta_2 \, x_{Ai} + \beta_3 \, x_{Bi} + \beta_5 \, x_{1i} \, x_{Bi} + \varepsilon_i$
  \item $y_i = \beta_0 + \beta_1 \, x_{1i} + \beta_2 \, x_{Ai} + \beta_3 \, x_{Bi} + \beta_4 \, x_{1i} \, x_{Ai} + \varepsilon_i$
\end{enumerate}
```
### ii) Interpretação de coeficientes de regressão de fatores de interação

Agora experimentamos ajustar exatamente o modelo (\ref{modelo_dummy}) e, conforme suspeitas, verificamos que não apenas agora o coeficiente $\beta_3$, correspondente ao tratamento B puro, é significativamente diferente de zero, como a interação dos tratamentos também o é.

```{r modelo-interacao}
#modelo aditivo (.) + interações específicas'
fit_depressao_intera <- lm(eficacia ~ (.) + idade*A + idade*B, data = dados_dummy)

fit_depressao_intera %>%
  summary() %>% 
  tidy() %>%
  knitr::kable(
    format = "latex",
    align = c("lcccc"),
    booktabs = TRUE,
    longtable = TRUE,
    linesep = "",
    escape = FALSE,
    digits = 3,
    col.names = c("Coeficiente","Estimativa", "EP" , "Estatística t", "p-valor"),
    caption = "Modelo de regressão linear para tratamentos com interação com idade sobre eficácia"
    ) %>%
  kableExtra::kable_styling(
      position = "center",
      latex_options = c("striped", "repeat_header"),
      stripe_color = "gray!15")


```

Se avaliarmos os estimadores por intervalos de confianca a 95% de significância, apenas o intercepto compreende zero. De fato, dada a magnitude do intervalo, isto é consonante com o p-valor obtido para este estimador, de 0.07. Este valor está um pouco acima da significância sugerida, mas decide-se por mantê-lo por interpretabilidade do modelo.

```{r confint-interacoes}

nomes <- row.names(confint(fit_depressao_intera, level=0.95))

tabela <- confint(fit_depressao_intera, level=0.95) %>% 
  as_tibble() %>%
  mutate(Estimador = nomes) %>%
  dplyr::select(Estimador, everything()) 

tabela %>%
  knitr::kable(
    format = "latex",
    align = c("lcc"),
    booktabs = TRUE,
    longtable = TRUE,
    linesep = "",
    escape = FALSE,
    digits = 3,
    col.names = c("Estimador","LI(2.5\\%)", "LS(97.5\\%)"),
    caption = "Intervalos de confiança para estimadores dos coeficientes de regressão") %>%
  kableExtra::kable_styling(
      position = "center",
      latex_options = c("striped", "repeat_header"),
      stripe_color = "gray!15")

```

Há várias mudanças na interpretação dos coeficientes estimados em relação ao primeiro modelo ajustado. Primeiramente, vemos que o efeito mínimo dos tratamentos está bem diferente, com interceptos $C<B<A$ e uma grande diferença entre o primeiro e último tratamento.

O efeito da interação entre idade e tratamentos pode ser melhor explicada se analisarmos graficamente primeiro. A figura a seguir ilustra as curvas de regressão para cada tratamento.

{{< pagebreak >}}

```{r, fig.align='center', fig.cap= "Curvas de regressão para modelo com interações.", fig.width=5, fig.height=3.5}
ggplot(dados, aes(x = idade, y = eficacia, color = tratamento))+
  geom_point(shape = 15, size = 2, alpha = .75)+
  geom_smooth(method = "lm", se = FALSE)+
  labs(y = "Eficácia", x = "Idade", color = "Tratamento")+
  theme_bw()+
  theme(axis.ticks = element_blank())
```

Cabe recapitularmos que o grupo de referência é o tratamento C, o que força a interpretação de que o intercepto $\beta_0$ do modelo é o seu efeito de tratamento isolado e $\beta_1 \, x_{1i}$ se refere à interação entre o tratamento C e a variável idade.

Podemos expressar então o modelo ajustado da seguinte forma:

```{=tex}
\begin{align}
   \hat{y}_i &= \hat{\beta_0} + \hat{\beta_1} \, x_{1i} + \hat{\beta_2} \, x_{Ai} + \hat{\beta_3} \, x_{Bi} + \hat{\beta_4} \, x_{1i} \, x_{Ai} +\hat{\beta_5} \, x_{1i} \, x_{Bi} \nonumber \\
   \nonumber \\
   &= \begin{cases}
        \hat{\beta_0} + \hat{\beta_1} \, x_{1i}, \text{ se tratamento C} \\
        (\hat{\beta}_0 + \hat{\beta}_2) + (\hat{\beta}_1 + \hat{\beta}_4) x_{1i},  \text{ se tratamento A} \\
        (\hat{\beta}_0 + \hat{\beta}_3) + (\hat{\beta}_1 + \hat{\beta}_5) x_{1i},  \text{ se tratamento B}
      \end{cases} \nonumber \\
      \nonumber \\
  &= \begin{cases}
        6.21 + 1.03 \, x_{1i}, \text{ se tratamento C} \\
        47.51 + 0.33 \,  x_{1i},  \text{ se tratamento A} \\
        28.91 + 0.53 \,  x_{1i},  \text{ se tratamento B}
  \end{cases}\label{modelo_decomposto}
\end{align}
```
Em termos reais, o modelo sugere que há uma grande influência da idade sobre a eficácia do tratamento C, enquanto essa influência é menor para o tratamento B e menor ainda para o tratamento A.

### iii) Tabela ANOVA

Finalmente, montamos a tabela de ANOVA do modelo. Em contraposição ao modelo anterior, sem interações, vemos que uma pequena parcela da soma de quadrados é atribuída aos resíduos. De fato, o coeficiente associado ao efeito puro do tratamento B ainda explica muito pouco da variação do modelo. No entanto, para que possamos considerar a interação Idade $\times$ Tratamento B, que testa significativamente para $H_a: \beta_j \neq 0$, mantemos o efeito puro.

```{r anova-modelo-interacoes}
anova(fit_depressao_intera) %>%
  tidy() %>%
  knitr::kable(
    format = "latex",
    align = c("lcccc"),
    booktabs = TRUE,
    longtable = TRUE,
    linesep = "",
    escape = FALSE,
    digits = 3,
    col.names = c("Fonte de Var.","g.l.", "SQ" , "QM", "F", "p-valor"),
    caption = "Tabela ANOVA para o modelo linear com interações"
    ) %>%
  kableExtra::kable_styling(
      position = "center",
      latex_options = c("striped", "repeat_header"),
      stripe_color = "gray!15")
```

### iv) Análise completa dos resíduos do modelo

Iniciamos a análise dos resíduos do modelo, supondo-se que $\varepsilon_i \sim N(0, \sigma^2)$, com testes de hipótese para normalidade, heteroscedasticidade e independência dos dados. Avaliando apenas os p-valores dos testes, não rejeitamos as hipóteses nulas e podemos considerar a normalidade dos resíduos, constância da variância e independência dos dados.

```{r testes-hipotese}
bind_rows(
  ## Perform the normal Shapiro-Wilk test for the residuals
  shapiro.test(residuals(fit_depressao_intera)) %>% tidy(),
  
  ## Perform breush-pagan test for hetereocedascity
  (bptest(fit_depressao_intera) %>% tidy())[, c(1, 2, 4)],
  
  ## Perform Durbin-Watson test for Independence
  (durbinWatsonTest(fit_depressao_intera) %>% tidy())[,c(1, 2, 4)]
) %>%
  dplyr::select(method, everything()) %>%
  knitr::kable(
    format = "latex",
    align = c("lcc"),
    booktabs = TRUE,
    longtable = TRUE,
    linesep = "",
    escape = FALSE,
    digits = 3,
    col.names = c("Teste","Estatística de teste","p-valor"),
    caption = "Testes de hipótese para normalidade, heteroscedasticidade e independência."
    ) %>%
  kableExtra::kable_styling(
      position = "center",
      latex_options = c("striped", "repeat_header"),
      stripe_color = "gray!15")
  
```

Se analisarmos graficamente, notamos que os resíduos parecem uniformemente distribuídos em torno de zero e com caudas mais pesadas no QQplot. Isto favorece a hipótese de não normalidade, mas contradiz os resultados do teste realizado. Verificaremos isso mais adiante.

Além disso, se avaliamos o gráfico de resíduos por sua alavancagem, vemos que há alguns pontos com distância de Cook muito próxima a dois. De fato, se utilizamos a função `stats::influence.measures()` encontramos 4 pontos de alavancagem por algum dos critérios apresentados. No entanto, nenhum deles está discrepante em ambos os eixos, de modo que podemos considerá-los bons pontos de alavancagem.

```{r, fig.align='center', fig.width=6.5, fig.height=6.5}
#rstudent(fit_depressao_intera) %>% plot()
par(mfrow=c(2,2))
plot(fit_depressao_intera)

#influence.measures(fit_depressao_intera)
```

Por fim, investigamos um pouco melhor os resíduos studentizados, gerando um evenlopamento por bootstrap paramétrico[^1]. De fato há pontos na borda da região designada como intervalo de confiança. No entanto, considerando a distância deles ao intervalo e os resultados dos demais testes, mantemos a afirmação de normalidade dos resíduos e não são propostos mais ajustes ao modelo.

[^1]: <https://github.com/cesar-galvao/modelos_lineares/blob/main/envelope_function.R>

```{r, fig.width = 5, fig.height = 4, fig.align='center'}
source("dados lista 2/envelope_function.R")
envelope_LR(fit_depressao_intera, OLS = T, main.title = "Resíduos com envelope")
```

# Apêndice

Todo o projeto de composição deste documento pode ser encontrado aqui: <https://github.com/cesar-galvao/mlg>

```{r codigo, eval = FALSE, echo = TRUE}

if(!("pacman" %in% installed.packages())){install.packages("pacman")}

pacman::p_load(tidyverse, tidymodels, kableExtra, corrplot, plotrix, lmtest, psych, car, phia, cowplot)


dados <- read.table("dados lista 2/Q02_data.txt", header=T)

dados %>%
  ggplot(aes(eficacia))+
  geom_histogram(color = "black", fill = "gray", bins = 10)+
  scale_y_continuous(limits = c(0, 9),
                     expand = expansion(mult = 0, add = 0))+
  labs(x = "Eficácia", y = "")+
  theme_bw()+
  theme(axis.ticks = element_blank())

dados %>%
  ggplot(aes(eficacia, fill = tratamento))+
  geom_histogram(bins = 10, color = "black")+
  scale_y_continuous(limits = c(0, 5),
                     expand = expansion(mult = 0, add = 0))+
  labs(x = "Eficácia", y = "", fill = "Tratamento")+
  theme_bw()+
  theme(axis.ticks = element_blank())+
  facet_wrap(~tratamento)

geral <- ggplot(dados, aes(x = idade, y = eficacia))+
  geom_point(shape = 15, size = 2, alpha = .75)+
  geom_smooth(method = "lm", se = FALSE)+
  labs(y = "Eficácia", x = "Idade")+
  theme_bw()+
  theme(axis.ticks = element_blank())

trat <- ggplot(dados, aes(x = idade, y = eficacia, color = tratamento))+
  geom_point(shape = 15, size = 2, alpha = .75)+
  labs(y = "Eficácia", x = "Idade")+
  theme_bw()+
  theme(axis.ticks = element_blank(),
        legend.position = "none")

plot_grid(geral, trat)

#da encoding à variavel tratamento
dados_dummy <- dados %>%
  mutate(A = if_else(tratamento == "A", 1, 0),
         B = if_else(tratamento == "B", 1, 0)) %>%
  dplyr::select(-tratamento)

#monta fit aditivo do modelo
fit_depressao <- lm(eficacia ~ (.), data = dados_dummy)

#tabela do modelo
fit_depressao %>%
  summary() %>% 
  tidy()

anova(fit_depressao) %>%
  tidy()

fit_depressao_intera <- lm(eficacia ~ (.) + idade*A + idade*B, data = dados_dummy)

fit_depressao_intera %>%
  summary() %>% 
  tidy()

nomes <- row.names(confint(fit_depressao_intera, level=0.95))

tabela <- confint(fit_depressao_intera, level=0.95) %>% 
  as_tibble() %>%
  mutate(Estimador = nomes) %>%
  dplyr::select(Estimador, everything()) 

ggplot(dados, aes(x = idade, y = eficacia, color = tratamento))+
  geom_point(shape = 15, size = 2, alpha = .75)+
  geom_smooth(method = "lm", se = FALSE)+
  labs(y = "Eficácia", x = "Idade", color = "Tratamento")+
  theme_bw()+
  theme(axis.ticks = element_blank())

anova(fit_depressao_intera) %>%
  tidy()

bind_rows(
  ## Perform the normal Shapiro-Wilk test for the residuals
  shapiro.test(residuals(fit_depressao_intera)) %>% tidy(),
  
  ## Perform breush-pagan test for hetereocedascity
  (bptest(fit_depressao_intera) %>% tidy())[, c(1, 2, 4)],
  
  ## Perform Durbin-Watson test for Independence
  (durbinWatsonTest(fit_depressao_intera) %>% tidy())[,c(1, 2, 4)]
) %>%
  dplyr::select(method, everything())

par(mfrow=c(2,2))
plot(fit_depressao_intera)

source("dados lista 2/envelope_function.R")
envelope_LR(fit_depressao_intera, OLS = T, main.title = "Resíduos com envelope")

```

```{r include = FALSE}
rm(list = ls())
gc()
```
