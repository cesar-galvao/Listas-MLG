---
title: "Lista 2"
subtitle: "Modelos Lineares Generalizados - 2/2023" 
author:
  - César Augusto Galvão - 19/0011572
  - Laiza Mendes - 20/0067028
format: 
  pdf:
    toc: true
    toc-depth: 2
    keep-tex: true
    include-in-header:
      text: |
        \usepackage[auth-lg]{authblk}
execute:
  echo: false
  message: false
  warning: false
---

{{< pagebreak >}}

```{r setup, include = FALSE}
if(!("pacman" %in% installed.packages())){install.packages("pacman")}

pacman::p_load(tidyverse, tidymodels, kableExtra, corrplot, plotrix, lmtest, psych, car, phia, stargazer)
```


# Questão 1

Considere os dados sobre a qualidade do vinho tinto, apresentados no ficheiro `Q01-data.txt`. Ajuste o modelo de regressão linear múltipla, e faça uma análise completa
desses dados. Que conclusões você tira dessa análise? (use 5% de significância durantes
as análises).

## a) Proponha algum método para resolver o problema da multicolinearidade no conjunto de dados

## b) Usando algum método de seleção de variáveis, obtenha o modelo final para o conjunto de dados

## c) Apresente a tabela de Análise de Variância para testar a significância global dos coeficientes do modelo final. Apresente as hipóteses de teste e conclua.

## d) Com base no modelo obtido no item anterior, faça uma análise de resíduos e conclua.



```{r EXEMPLO-TABELA}
# kpss.test(E) %>% 
#   tidy()%>%
#   select(method, statistic, `p.value`) %>%
#   knitr::kable(
#     format = "latex",
#     align = c("lccc"),
#     booktabs = TRUE,
#     longtable = TRUE,
#     linesep = "",
#     escape = FALSE,
#     digits = 2,
#     col.names = c("", "Estatística", "p-valor")
#     ) %>%
#   kableExtra::kable_styling(
#       position = "center",
#       latex_options = c("striped", "repeat_header"),
#       stripe_color = "gray!15")
```

# Questão 2

Uma equipe de pesquisadores de saúde mental deseja comparar três métodos de tratamento da depressão grave (A, B e C=referência). Eles também gostariam de estudara relação entre idade e eficácia do tratamento, bem como a interação (se houver) entre idade e tratamento. Cada elemento da amostra aleatória simples de 36 pacientes, foi selecionado aleatoriamente para receber o tratamento A, B ou C. Os dados obtidos podem ser encontrados no ficheiro `Q02-data.txt`. A variável dependente $y$ é a eficácia do tratamento; as variáveis independentes são: a idade do paciente no aniversário mais próximo e o tipo de tratamento administrado (use 1% de significância durantes as análises).

Uma amostra dos dados é exibida na tabela a seguir:

```{r dados-q2}

dados <- read.table("dados lista 2/Q02_data.txt", header=T)

head(dados)%>%
  knitr::kable(
    format = "latex",
    align = c("c"),
    booktabs = TRUE,
    longtable = TRUE,
    linesep = "",
    escape = FALSE,
    digits = 2
    ) %>%
  kableExtra::kable_styling(
      position = "center",
      latex_options = c("striped", "repeat_header"),
      stripe_color = "gray!15")

```

## a) Ajuste um modelo de regressão linear e interprete os resultados obtidos

Temos um potencial modelo de regressão linear que pode ou não conter interações entre as variáveis, o qual pode ser expresso em sua forma saturada, em que $X_1$ é a variável idade e $X_2$ a variável tratamento


\begin{align}
  y_i = \beta_0 + \beta_1 \, x_{1i} + \beta_2 \, x_{2i} + \beta_3 \, x_{1i}\, x_{2i} + \varepsilon_i, \quad i = 1, 2, \dots, n
\end{align}

ou, de forma análoga, desmembrando $X_2$ em variáveis *dummy* $X_A$ e $X_B$, indicadores da presença do tratamento $A$ e $B$, ambas assumindo valor $0$ quando se trata do tratamento $C$


\begin{align}
  y_i = \beta_0 + \beta_1 \, x_{1i} + \beta_2 \, x_{Ai} + \beta_3 \, x_{Bi} + \beta_4 \, x_{1i} \, x_{Ai} + \beta_5 \, x_{1i} \, x_{Bi} + \varepsilon_i. \label{modelo_dummy}
\end{align}

Se simplesmente ajustamos um modelo de regressão linear -- sem os termos de interação -- utilizando (\ref{modelo_dummy}) como referência na função `lm()`, obtemos os seguintes resultados:

```{r ajuste-modelo2}
#da encoding à variavel tratamento
dados_dummy <- dados %>%
  mutate(A = if_else(tratamento == "A", 1, 0),
         B = if_else(tratamento == "B", 1, 0)) %>%
  select(-tratamento)

#monta fit aditivo do modelo
fit_depressao <- lm(eficacia ~ (.), data = dados_dummy)

#tabela do modelo
fit_depressao %>%
  summary() %>% 
  tidy() %>%
  knitr::kable(
    format = "latex",
    align = c("lcccc"),
    booktabs = TRUE,
    longtable = TRUE,
    linesep = "",
    escape = FALSE,
    digits = 3,
    col.names = c("Coeficiente","Estimativa", "EP" , "Estatística t", "p-valor"),
    caption = "Modelo de regressão linear para tratamentos sem interação com idade sobre eficácia"
    ) %>%
  kableExtra::kable_styling(
      position = "center",
      latex_options = c("striped", "repeat_header"),
      stripe_color = "gray!15")
```


Ou seja, se considerarmos independentemente idade, tratamento A e tratamento B, podemos considerar que:

* Há uma linha de base na eficácia de aproximadamente 22.3, i.e. sob o tratamento C;
* A eficácia base para o tratamento A é de 32.3;
* A eficácia base para o tratamento B é de 22.75 -- mas poderíamos desconsiderar este coeficiente, se nos guiarmos pelo p-valor; 
* Cada ano a mais de vida incrementa a eficácia em 0.644.

É possível considerar que um tamanho de amostra pequeno tenha grande influência sobre a significância de $H_0: \beta_3 = 0$ do modelo. No entanto, trata-se de um fenômeno para o qual o tratamento pode estar estreitamente associado à idade, caso em que teríamos que considerar o modelo (\ref{modelo_dummy}) por completo.


## b) Obtenha a tabela ANOVA para o modelo obtido no item (a) e interprete os resultados

Se montarmos uma tabela de Análise de Variância para o modelo de regressão linear ajustado, obtemos os resultados a seguir:

```{r anova-fit-depressao}
anova(fit_depressao) %>%
  tidy() %>%
  knitr::kable(
    format = "latex",
    align = c("lcccc"),
    booktabs = TRUE,
    longtable = TRUE,
    linesep = "",
    escape = FALSE,
    digits = 3,
    col.names = c("Fonte de Var.","g.l.", "SQ" , "QM", "F", "p-valor"),
    caption = "Tabela ANOVA para o modelo linear sem interações"
    ) %>%
  kableExtra::kable_styling(
      position = "center",
      latex_options = c("striped", "repeat_header"),
      stripe_color = "gray!15")
```

Nota-se que a maioria da variância explicada pelo modelo está associada à variável idade, enquanto a soma de quadrados das variáveis de tratamento juntas não superam a soma de quadrados dos resíduos.

Se conjugarmos os resultados deste item com os do item a) vemos que isoladamente apenas idade, e interessantemente apenas o tratamento A, parecem ser variáveis que realmente contribuem para a explicação do fenômeno. 

## c) Considere a possibilidade de incluir a interação entre as varáveis independentes

Supõe-se que $\varepsilon_i \sim N(0, \sigma^2)$. 

### i) Lista de todos os submodelos possíveis 

A partir do modelo (\ref{modelo_dummy}), construimos todos os possíveis submodelos. Considerando que temos três covariáveis e dois termos de interação, temos $\sum\limits_{n = 1}^5\binom{6}{n} = 62$ modelos

\begin{enumerate}
  \item $y_i = \beta_0 + \varepsilon_i$
  \item $y_i = \beta_1 \, x_{1i} + \varepsilon_i$
  \item $y_i = \beta_2 \, x_{Ai} + \varepsilon_i$
  \item $y_i = \beta_3 \, x_{Bi} + \varepsilon_i$
  \item $y_i = \beta_4 \, x_{1i} \, x_{Ai} + \varepsilon_i$
  \item $y_i = \beta_5 \, x_{1i} \, x_{Bi} + \varepsilon_i$
  
 
  \item $y_i = \beta_0 + \beta_1 \, x_{1i} + \varepsilon_i$
  \item $y_i = \beta_0 + \beta_2 \, x_{Ai} + \varepsilon_i$
  \item $y_i = \beta_0 + \beta_3 \, x_{Bi} + \varepsilon_i$
  \item $y_i = \beta_0 + \beta_4 \, x_{1i} \, x_{Ai} + \varepsilon_i$
  \item $y_i = \beta_0 + \beta_5 \, x_{1i} \, x_{Bi} + \varepsilon_i$
  \item $y_i = \beta_1 \, x_{1i} + \beta_2 \, x_{Ai} + \varepsilon_i$
  \item $y_i = \beta_1 \, x_{1i} + \beta_3 \, x_{Bi} + \varepsilon_i$
  \item $y_i = \beta_1 \, x_{1i} + \beta_4 \, x_{1i} \, x_{Ai} + \varepsilon_i$
  \item $y_i =  \beta_1 \, x_{1i} + \beta_5 \, x_{1i} \, x_{Bi} + \varepsilon_i$
  \item $y_i = \beta_2 \, x_{Ai} + \beta_3 \, x_{Bi}+ \varepsilon_i$
  \item $y_i = \beta_2 \, x_{Ai} + \beta_4 \, x_{1i} \, x_{Ai} + \varepsilon_i$
  \item $y_i = \beta_2 \, x_{Ai} + \beta_5 \, x_{1i} \, x_{Bi} + \varepsilon_i$
  \item $y_i = \beta_3 \, x_{Bi} + \beta_4 \, x_{1i} \, x_{Ai} + \varepsilon_i$
  \item $y_i = \beta_3 \, x_{Bi} \beta_5 \, x_{1i} \, x_{Bi} + \varepsilon_i$
  \item $y_i = \beta_4 \, x_{1i} \, x_{Ai} + \beta_5 \, x_{1i} \, x_{Bi} + \varepsilon_i$
  
  

  \item $y_i = \beta_0 + \beta_1 \, x_{1i} + \beta_2 \, x_{Ai} + \varepsilon_i$
  \item $y_i = \beta_0 + \beta_1 \, x_{1i} + \beta_3 \, x_{Bi} + \varepsilon_i$
  \item $y_i = \beta_0 + \beta_1 \, x_{1i} + \beta_4 \, x_{1i} \, x_{Ai} + \varepsilon_i$
  \item $y_i = \beta_0 + \beta_1 \, x_{1i} + \beta_5 \, x_{1i} \, x_{Bi} + \varepsilon_i$
  \item $y_i = \beta_0 + \beta_2 \, x_{Ai} + \beta_3 \, x_{Bi} + \varepsilon_i$
  \item $y_i = \beta_0 + \beta_2 \, x_{Ai} + \beta_4 \, x_{1i} \, x_{Ai} +  \varepsilon_i$
  \item $y_i = \beta_0 + \beta_2 \, x_{Ai} + \beta_5 \, x_{1i} \, x_{Bi} + \varepsilon_i$
  \item $y_i = \beta_0 + \beta_3 \, x_{Bi} + \beta_4 \, x_{1i} \, x_{Ai} +  \varepsilon_i$
  \item $y_i = \beta_0 + \beta_3 \, x_{Bi} + \beta_5 \, x_{1i} \, x_{Bi} + \varepsilon_i$
  \item $y_i = \beta_0 + \beta_4 \, x_{1i} \, x_{Ai} + \beta_5 \, x_{1i} \, x_{Bi} + \varepsilon_i$
  \item $y_i = \beta_1 \, x_{1i} + \beta_2 \, x_{Ai} + \beta_3 \, x_{Bi} + \varepsilon_i$
  \item $y_i = \beta_1 \, x_{1i} + \beta_2 \, x_{Ai} + \beta_4 \, x_{1i} \, x_{Ai} + \varepsilon_i$
  \item $y_i = \beta_1 \, x_{1i} + \beta_2 \, x_{Ai} + \beta_5 \, x_{1i} \, x_{Bi} + \varepsilon_i$
  \item $y_i = \beta_1 \, x_{1i} + \beta_3 \, x_{Bi} + \beta_4 \, x_{1i} \, x_{Ai} + \varepsilon_i$
  \item $y_i = \beta_1 \, x_{1i} + \beta_3 \, x_{Bi} + \beta_5 \, x_{1i} \, x_{Bi} + \varepsilon_i$
  \item $y_i = \beta_1 \, x_{1i} + \beta_4 \, x_{1i} \, x_{Ai} + \beta_5 \, x_{1i} \, x_{Bi} + \varepsilon_i$
  \item $y_i = \beta_2 \, x_{Ai} + \beta_3 \, x_{Bi} + \beta_4 \, x_{1i} \, x_{Ai} + \varepsilon_i$
  \item $y_i = \beta_2 \, x_{Ai} + \beta_3 \, x_{Bi} + \beta_5 \, x_{1i} \, x_{Bi} + \varepsilon_i$
  \item $y_i = \beta_2 \, x_{Ai} + \beta_4 \, x_{1i} \, x_{Ai} + \beta_5 \, x_{1i} \, x_{Bi} + \varepsilon_i$
  \item $y_i = \beta_3 \, x_{Bi} + \beta_4 \, x_{1i} \, x_{Ai} + \beta_5 \, x_{1i} \, x_{Bi} + \varepsilon_i$
  

 
  \item $y_i = \beta_0 + \beta_1 \, x_{1i} + \beta_2 \, x_{Ai} + \beta_3 \, x_{Bi} + \varepsilon_i$
  \item $y_i = \beta_0 + \beta_1 \, x_{1i} + \beta_2 \, x_{Ai} + \beta_4 \, x_{1i} \, x_{Ai} + \varepsilon_i$
  \item $y_i = \beta_0 + \beta_1 \, x_{1i} + \beta_2 + \beta_5 \, x_{1i} \, x_{Bi} + \varepsilon_i$
  \item $y_i = \beta_0 + \beta_1 \, x_{1i} + \beta_3 \, x_{Bi} + \beta_4 \, x_{1i} \, x_{Ai} + \varepsilon_i$
  \item $y_i = \beta_0 + \beta_1 \, x_{1i} + \beta_3 \, x_{Bi} + \beta_5 \, x_{1i} \, x_{Bi} + \varepsilon_i$
  \item $y_i = \beta_0 + \beta_1 \, x_{1i} + \beta_4 \, x_{1i} \, x_{Ai} + \beta_5 \, x_{1i} \, x_{Bi} + \varepsilon_i$
  
  \item $y_i = \beta_0 + \beta_2 \, x_{Ai} + \beta_3 \, x_{Bi} + \beta_4 \, x_{1i} \, x_{Ai} + \varepsilon_i$
  \item $y_i = \beta_0 + \beta_2 \, x_{Ai} + \beta_3 \, x_{Bi} + \beta_5 \, x_{1i} \, x_{Bi} + \varepsilon_i$
  \item $y_i = \beta_0 + \beta_2 \, x_{Ai} + \beta_4 \, x_{1i} \, x_{Ai} + \beta_5 \, x_{1i} \, x_{Bi} + \varepsilon_i$
  \item $y_i = \beta_0 + \beta_3 \, x_{Bi} + \beta_4 \, x_{1i} \, x_{Ai} + \beta_5 \, x_{1i} \, x_{Bi} + \varepsilon_i$
  
  \item $y_i = \beta_1 \, x_{1i} + \beta_2 \, x_{Ai} + \beta_3 \, x_{Bi} + \beta_4 \, x_{1i} \, x_{Ai} + \varepsilon_i$
  \item $y_i = \beta_1 \, x_{1i} + \beta_2 \, x_{Ai} + \beta_3 \, x_{Bi} + \beta_5 \, x_{1i} \, x_{Bi} + \varepsilon_i$
  \item $y_i = \beta_1 \, x_{1i} + \beta_2 \, x_{Ai} + \beta_4 \, x_{1i} \, x_{Ai} + \beta_5 \, x_{1i} \, x_{Bi} + \varepsilon_i$
  \item $y_i = \beta_1 \, x_{1i} + \beta_3 \, x_{Bi} + \beta_4 \, x_{1i} \, x_{Ai} + \beta_5 \, x_{1i} \, x_{Bi} + \varepsilon_i$
  
  \item $y_i = \beta_2 \, x_{Ai} + \beta_3 \, x_{Bi} + \beta_4 \, x_{1i} \, x_{Ai} + \beta_5 \, x_{1i} \, x_{Bi} + \varepsilon_i$
  
  \item $y_i = \beta_1 \, x_{1i} + \beta_2 \, x_{Ai} + \beta_3 \, x_{Bi} + \beta_4 \, x_{1i} \, x_{Ai} + \beta_5 \, x_{1i} \, x_{Bi} + \varepsilon_i$
  
  \item $y_i = \beta_0 + \beta_2 \, x_{Ai} + \beta_3 \, x_{Bi} + \beta_4 \, x_{1i} \, x_{Ai} + \beta_5 \, x_{1i} \, x_{Bi} + \varepsilon_i$
  \item $y_i = \beta_0 + \beta_1 \, x_{1i} + \beta_3 \, x_{Bi} + \beta_4 \, x_{1i} \, x_{Ai} + \beta_5 \, x_{1i} \, x_{Bi} + \varepsilon_i$
  \item $y_i = \beta_0 + \beta_1 \, x_{1i} + \beta_2 \, x_{Ai} + \beta_4 \, x_{1i} \, x_{Ai} + \beta_5 \, x_{1i} \, x_{Bi} + \varepsilon_i$
  \item $y_i = \beta_0 + \beta_1 \, x_{1i} + \beta_2 \, x_{Ai} + \beta_3 \, x_{Bi} + \beta_5 \, x_{1i} \, x_{Bi} + \varepsilon_i$
  \item $y_i = \beta_0 + \beta_1 \, x_{1i} + \beta_2 \, x_{Ai} + \beta_3 \, x_{Bi} + \beta_4 \, x_{1i} \, x_{Ai} + \varepsilon_i$
\end{enumerate}

### ii) Interpretação de coeficientes de regressão de fatores de interação

Agora experimentamos ajustar exatamente o modelo (\ref{modelo_dummy}) e, conforme suspeitas, verificamos que não apenas agora o coeficiente $\beta_3$, correspondente ao tratamento B, é significativamente diferente de zero, como a interação dos tratamentos também o é.

```{r modelo-interacao}
#modelo aditivo (.) + interações específicas'
fit_depressao_intera <- lm(eficacia ~ (.) + idade*A + idade*B, data = dados_dummy)

fit_depressao_intera %>%
  summary() %>% 
  tidy() %>%
  knitr::kable(
    format = "latex",
    align = c("lcccc"),
    booktabs = TRUE,
    longtable = TRUE,
    linesep = "",
    escape = FALSE,
    digits = 3,
    col.names = c("Coeficiente","Estimativa", "EP" , "Estatística t", "p-valor"),
    caption = "Modelo de regressão linear para tratamentos com interação com idade sobre eficácia"
    ) %>%
  kableExtra::kable_styling(
      position = "center",
      latex_options = c("striped", "repeat_header"),
      stripe_color = "gray!15")


```

Há várias mudanças na interpretação dos coeficientes estimados em relação ao primeiro modelo ajustado. Primeiramente, vemos que a linha de base dos tratamentos está bem diferente  com efeitos $C<B<A$, com uma grande diferença entre o primeiro e último tratamento.

O efeito da interação entre idade e tratamentos pode ser melhor explicada se analisarmos graficamente primeiro. A figura a seguir ilustra as curvas de regressão para cada tratamento.


```{r, fig.align='center', fig.cap= "Curvas de regressão para modelo com interações."}
ggplot(dados, aes(x = idade, y = eficacia, color = tratamento))+
  geom_point(shape = 15, size = 2, alpha = .75)+
  geom_smooth(method = "lm", se = FALSE)+
  labs(y = "Eficácia", x = "Idade", color = "Tratamento")+
  theme_bw()+
  theme(axis.ticks = element_blank())
```

Cabe recapitularmos que o grupo de referência é o tratamento C, o que força a interpretação de que o intercepto $\beta_0$ do modelo é o seu efeito de tratamento isolado e $\beta_1 \, x_{1i}$ se refere à interação entre o tratamento C e a variável idade. 

Enquanto este coeficiente, do grupo de referência, é positivo e muito próximo a $1$, os demais são negativos. No entanto, isto não significa que suas retas têm coeficiente angular negativo. O sentido e magnitude desses estimadores indica quanto a inclinação das demais retas está deslocada no sentido horário em relação à referência. Pela tabela, notamos que $\beta_1 > \beta_4 > \beta_5$. Analogamente, se $\theta_j, j = A, B, C$ for o ângulo da curva de regressão em relação às abscissas, notamos que $\theta_C > \theta_B > \theta_A$.

Em termos reais, o modelo sugere que há uma grande influência da idade sobre a eficácia do tratamento C, enquanto essa influência é menor para o tratamento B e menor ainda para o tratamento A.


### iii) tabela ANOVA

descrever tabela anova

```{r anova-modelo-interacoes}
anova(fit_depressao_intera) %>%
  tidy() %>%
  knitr::kable(
    format = "latex",
    align = c("lcccc"),
    booktabs = TRUE,
    longtable = TRUE,
    linesep = "",
    escape = FALSE,
    digits = 3,
    col.names = c("Fonte de Var.","g.l.", "SQ" , "QM", "F", "p-valor"),
    caption = "Tabela ANOVA para o modelo linear com interações"
    ) %>%
  kableExtra::kable_styling(
      position = "center",
      latex_options = c("striped", "repeat_header"),
      stripe_color = "gray!15")
```


### iv) Análise completa dos resíduos do modelo



# Apêndice

Todo o projeto de composição deste documento pode ser encontrado aqui: <https://github.com/cesar-galvao/mlg>

```{r codigo, eval = FALSE, echo = TRUE}



```

```{r include = FALSE}
rm(list = ls())
gc()

```
